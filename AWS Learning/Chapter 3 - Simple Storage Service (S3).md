- ## S3 Security
	- private by default
	- the only identity that has access to the bucket is the Account ROOT user of the account that created that bucket
	
	- ### S3 Bucket policy
		- a form of **Resource Policy**
		- Like **identity policies, but attached to a bucket**
		- **Allow / Deny same or different accounts**
		- **Allow / Deny Anonymous principals**
		- Resource policies **have a specific field** (Principal: "*")
		- Bucket policies have conditions (through the Condition field)
			- ![[Pasted image 20240302194517.png]]***e.g. Allow access to bucket to all principals except the IP Address 1.3.3.7/32***
		
	- ### Access Control Lists (ACLs)
		- ACLs can be put on objects and bucket
		- Legacy stuff, not recommended by AWS
		- A subresource
		- Inflexible and simple permissions (*READ, WRITE, READ_ACP, WRITE_ACP, FULL_CONTROL*)
		
	- ### Block Public Access Settings
		- These apply to all public access, not intra cloud IAM identities!!!

- ## S3 Static Hosting
	
	- Allows access via **HTTP**
	- **Index** and **Error** documents are set to specific objects in S3
	- Website endpoint is created
	- Custom Domain via **R53** - **BUCKETNAME MATTERS**

- ## Object Versioning & MFA Delete
	
	- ### Object versioning
		- **disabled by default**
		- **once enabled it can't be disabled**
		- an alternative is to **suspend** the bucket (if desired it can be re-enabled)
		
		- it lets you store **multiple versions of an object** in the **same bucket**
		- if you modify the object, it **generates a new version of that object**, leaving the original one in place
		- when the versioning is disabled the **ID** of the object is set to **NULL**
		- the **greatest ID value represents the latest / current version** (returned by default)
		
		- versioning also impacts **deletions**
		- if we want to delete an object and **we do not specify any ID**, the bucket will assume that we want to delete the **latest object version, along with all the previous versions**
		- the deletion is **not actually happening**, but a new version of that object, called a **DELETE MARKER**, is created, and it makes **all the versions under it look hidden**
		- If we delete the **DELETE MARKER the files are visible again**
		- In order to actually delete an object we have to specify the version ID
		- When the latest object is deleted, the previous version becomes the latest/current one
		- **!!!! STORAGE IS CONSUMED / BILLED FOR ALL VERSIONS OF THE OBJECT**
		- Only way to 0 costs is to delete the bucket
		
	- ### MFA Delete
		- **enabled in versioning config**
		- is required to **change bucket versioning state**
		- is required to **delete versions**
		- **in order to delete a version of an object we need to provide the serial number (MFA) + the Code Passed with API Calls**
		
- ## S3 Performance Optimisation
		
     ### One Stream
		
	-  By default, when you upload an object to S3 it is uploaded as **a huge blob in a single data stream**. The file becomes an object that will be uploaded using the PUT API. 
		- **This means that if the stream fails, the whole upload fails and requires full restart.**
		- Limit to 5GB
		
	 ### Multipart Upload
		
		- Data is broken into multiple parts
		- Min data size for multipart is **100MB**
		- 10000 max parts, 5MB to 5GB
		- Last part can be smaller than 5MB
		- Parts can fail, and be restarted
		- Transfer rate = speeds of all parts
		
     ### Accelerated Transfer
		
	- Using the network of AWS Edge Locations (to overcome long inefficient routings of data through the public internet )
	- Not always convenient **( in case there are a small number of hops )**

- ## Key Management Store (KMS)
	
	- Used by multiple AWS products
	- **Regional and Public** service (***stored in a region and never leave***)
	- Can create **Multi-region keys** if needed
	- **Create, Store and Manage Keys**
	- **Symmetric and Asymmetric** Keys
	- Cryptographic operations (encrypt, decrypt)
	- **Keys never leave KMS** - Provides Standard **FIPS 140-2 (L2)** <- Level 2 Compliance
	- **Policies are different for encryption and decryption**
	- **Supports Key Rotation**
	- *supports Aliases (also per region)*
	
	KMS Keys are a **container** for the logical key.
	**KMS Keys are logical - ID, Date, Policy, description and state**
	They can be **GENERATED or IMPORTED**, and can have up to **4KB of data**
	
	- ### How KMS works?
	
		1. Create a Key in KMS
		2. Encrypt data by sending it to KMS and specifying what key should be used
		3. Decrypt *(no need to specify the key - it is already specified in the cypher text of the data)*
		![[Screenshot 2024-03-05 at 01.44.19.png]]
	
	- ### Data Encryption Keys (DEKs)
		
		- generated by KMS
		- GenerateDataKey - works on data > 4KB
		- **not stored** in the KMS service - creates it and then discards it
		- *The KMS only creates the DEKs but does not use them for encryption - you do, or the service using the DEK*
		- **S3 can use KMS to encrypt every single object**
	
		 #### How do DEKs Work?
		
		1. Creates 2 keys *immediately before* you want to encrypt something : 
			1. **Plaintext Version**
			2. A Cypher text Version of that same encryption Key - ***encrypted using the KMS Key that generated it***
		2. Encrypt Data using plaintext key
		3. **Discard** plaintext key
		4. **Store** encrypted key **with the encrypted data**
		5. *For decryption* -> Pass the cypher text key to KMS to ***decrypt it using the same KMS key used to generate it***
		6. **Use the resulting key to decrypt the data**
		7. **Discard** the cypher text encryption key
		
	 ### Key policies and Security
		
	- **The account that created the key is immediately granted access to that key**
	- Key policies are ***Resource Policies***
	- Every key has one - ***for customer managed keys (created or imported manually by the user) we have to implement it, the self account trust is not automatic***
	- Better use **IAM Policies**
	- Supports **Grants**

- ## Object Encryption
	
	**Buckets are not encrypted! Objects are!!!**
	
	- ### Client Side Encryption (CSE)
		
		- data is encrypted before it's sent to the server
		- The user is responsible for recording which key is used for each object
		- The user controls the keys, process and tooling for encryption
		
	- ### Server Side Encryption (SSE)
		
		- The data is transmitted as plaintext.
		- Once it has arrived at the s3 endpoint, it is encrypted and stored into S3
		
		- #### Three types of SSE:
			1. **SSE-C (Server Side Encryption with customer provided keys)**
				
				- *The Object is sent as plaintext together with a key but it's encrypted in transit by the https, so the data is not visible.*
				- *In order to decrypt, we need to provide a request and the key (which will be discarded after decryption*
				- **Good for Heavy Regulation Environments**
				- ***Save on CPU compared to CSE (The encryption and decryption is done server-side)***
				- ![[Screenshot 2024-03-08 at 15.26.28.png]]
			
			2. **SSE-S3 (Server Side Encryption with AWS S3 Provided Keys) - *default***
				
				- AWS Handles both the encryption processes as well as the key generation
				- When we upload an object, AWS generates a key just for that object (per object key), and encrypts the object before storing it
				- Another key called an S3 key (invisible to the customer) is created, and it is used to encrypt the per object keys
				- **We are left with an cipher object and a cipher key** *(AES256)*
				- **Very Little Control (no access or rotation control of the keys)**
				- ![[Screenshot 2024-03-08 at 15.39.11.png]]
				
			3. **SSE-KMS (Server Side Encryption with KMS Keys stored in KMS Key Management Service)**
				
				- The power of this method comes from creating a **Customer Managed KMS Key** - managed by you and supports separated permissions
				- When we want to store an object into S3, the S3 Service makes a request to the existing KMS key and a Data Encryption Key is created
				- The DEKs are in 2 versions ( **one plain text and one cipher text**)
				- After the object is encrypted using the plain text key, it is discarded and only the cipher text key is stored with the object. (same architecture like per object keys, but these can be managed)
				- Provides control over KMS usage, rotation, logging, audit and **Role Separation**
				- **With No Access to KMS a person can't decrypt the encrypted key -> No decryption of the data**
				- ![[Screenshot 2024-03-08 at 15.48.56.png]]
				
	 ![[Screenshot 2024-03-08 at 15.51.21.png]]

- ## S3 Bucket Keys
	
	- In a scenario where **no Bucket keys** are used, **for every Object** that we want to store in S3 with encryption, we need a unique DEK (Data Encryption Key). ***Each DEK means an API Call to the KMS (take the kms key and generate the DEK)***.
	- Using a single KMS Key limits the number of PUTS that can be done to store encrypted objects / second / key
	- ![[Screenshot 2024-03-08 at 16.59.48.png]]
	
	
	- If we use ***The Bucket Keys***, the KMS Key is used to create a **time limited S3 Bucket Key** *(which will be used further to generate DEKs)* -> Offloads the work from KMS to S3 and improves scalability
	- ![[Screenshot 2024-03-08 at 17.02.00.png]]
	
	
	- **!!! After enabling Bucket Keys, in the CloudTrail KMS Logs we will se the bucket name, not the objects ---- due to the S3Bucket Key being used to generate the DEKs, not the KMS !!!**
	- Works with replication
	- When replicating plaintext to a bucket using bucket keys, the encryption is done at the destination (for more details visit [https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-key.html))

- ## S3 Object Storage Classes
	
	- The default storage class available is the **S3 Standard** 
		- *objects are replicated on at least 3 availability zones in the AWS region* - 11 9s durability (99.999999999%)
		- Replication and Content-MD5 Checksums and Cyclic Redundancy Checks (CRCs) are used to detect and fix any data corruption
		- **Billed per GB/month for data stored. A $ per GB charge for transfer OUT (IN is free) and a price per 1000 requests. No specific retrieval fee, minimum duration or size.**
		- data available within milliseconds and can be made publicly available![[Screenshot 2024-03-14 at 16.26.01.png]]
	
	- **S3 Standard-IA**
		- same as S3 Standard but more cost-effective
		- used for infrequent access
		- cost per retrieval
		- minimum duration charge of 30 days - objects can be stored for less, but the minimum billing always applies
		- minimum capacity charge of 128KB per object
		- **Should be used for long lived data, which is important but where access is infrequent**![[Screenshot 2024-03-14 at 16.27.21.png]]
	
	- **S3 One-Zone-IA**
		- Same as S3 IA, but data is stored in only one AZ (no replication)
		- Cheaper
		- **Used for non-critical data that is replaceable**![[Screenshot 2024-03-14 at 16.27.58.png]]
		
	- **S3 Glacier Instant**
		- Like ***S3 Standard IA*** but :
			- **cheaper storage**
			- **more expensive retrieval**
			- **longer minimum duration**
		- **For when we need Once per quarter instant access**![[Screenshot 2024-03-14 at 16.28.39.png]]
		
	- **S3 Glacier Flexible**
		- Same as S3 Standard but they are not immediately available
		- Objects cannot be made public -> requires a retrieval process
		- Data in Glacier Flexible is retrieved to **S3 Standard IA** temporarily:
			- *Expedited (1-5 min)*
			- **Standard(3-5 hours)**
			- ***bulk (5-12 hours)***
			- *faster ( more expensive )*
		- **40KB min size**
		- *90 day minimum duration*
		- **for Archival Data where frequent or realtime access isn't needed** ( yearly )![[Screenshot 2024-03-14 at 16.29.25.png]]
	
	- **S3 Glacier Deep Archive**
		- Objects cannot be made publicly accessible
		- *any access of data ( beyond object metadata ) requires a retrieval process*
		- Data in **Glacier Deep Archive** is retrieved to **S3 Standard IA** temporarily:
			- **Standard (12 hrs)**
			- **bulk (48 hrs)**
		- **40KB min size**
		- **180 Days min duration**
		- **Used for Archival data that rarely if ever needs to be accessed - Legal or Regulation Data Storage**![[Screenshot 2024-03-14 at 16.29.55.png]]
	
	- **S3 Intelligent Tiering**
		- monitors object access and moves it in certain tiers
		- adds a monitoring and automation cost per 1000 objects
		   -  ![[Screenshot 2024-03-14 at 16.33.52.png]]

- ## S3 Lifecycle 
	
	- A lifecycle is a **set of rules**
	- **Rules consist of actions on buckets or group of objects**
	- **Transition Actions**
	- *Expiration Actions*
	- **can't trigger actions based on access (S3 Intelligent tiering does that)**
	- ***S3 One Zone IA cannot Transition to Glacier Instant***! ![[Screenshot 2024-03-14 at 17.11.27.png]]
	- Transition can only happen down!

- ## S3 Replication
	- **Cross-Region Replication (CRR)**
	
	- **Same-Region Replication (SRR)**
	
	- **Same Account Replication**
		- Needs the Source Bucket and an IAM Role that assumes replication
		- Both buckets (destination and source) are in the same AWS Account -> they both trust the same AWS Account -> they trust IAM -> they trust the IAM Role
	
	- Different Account Replication
		- the destination bucket (replica) does not trust the source account
		- a bucket policy needs to be added to the destination account in order for the source account to be trusted
	
	**What to replicate?**
	- ***All objects or subsets***
	- ***storage class*** (default is to maintain, but we can opt for a cheaper storage class)
	- ***ownership*** - default is the source account
	- *Replication Time Control (RTC)* - adds monitoring for which objects are queued for replication
	
	**------IMPORTANT------**
	
	1. **The replication is not retroactive by default and versioning has to be turned on on both destination and source buckets! If we apply replication to a bucket that already has objects, they will not be replicated
	2. * **batch replication can be used if there are existing objects **
	3. **One-way replication (source -> destination), or bi-directional**
	4. Replication can be done either unencrypted, SSE-S3, SSE-KMS (extra configs) or SSE-C
	5. Source bucket owner needs PERMISSION to objects
	6. No System Events are replicated
	7. No Glacier or Glacier Deep Archive (conceptually separate storage products)
	8. **No deletes are replicated ( but the deleteMarkerReplication can be added )**
	
	**Why use Replication?**
	1. SRR - Log aggregation
	2. SRR - Prod and QA environment sync
	3. SRR - string sovereignty requirements
	4. CRR - global resilience
	5. CRR - reduce latency

- ## S3 Presigned URLs
	
	- grants an outside user / app temporary access to objects in a private s3
	- ![[Screenshot 2024-03-14 at 23.49.09.png]]
	- ![[Screenshot 2024-03-14 at 23.57.07.png]]Creation process
	- Must specify an object and an expiry date and time!
	- If a user doesn't have access to an object, the presigned URL created by that user will not have access to that object
	- Don't generate using an IAM Role -> URL permissions expire when the TempCredentials expire ( the URL could be valid much longer )

- ## S3 Select & Glacier Select
	
	- S3 is a very scalable storage
	- Used mostly for when we need an entire object
	- But if that object is 5TB, it takes a lot of time and bandwidth
	- Filtering at the client side is not a solution (consumption already happened)
	- S3/Glacier Select uses SQL-like syntax for selecting part of the objects, pre-filtered by S3
	- CSV, JSON, Parquet, BZIP2 compression for CSV and json
	- 400% faster, 80% cheaper

- ## S3 Cross-Origin Resource Sharing (CORS)
	
	- *Mostly used for API Gateways*
	
	- CORS Flow![[Screenshot 2024-03-15 at 00.32.35.png]]
	
	- CORS Configuration![[Screenshot 2024-03-15 at 00.34.41.png]]
	- ### Types of requests:
		- Simple requests
		- Pre-flight requests (browser first sends a HTTP request to the origin and will determine if the origin is safe)
		- **Access-Control-Allow-Origin** (contains * or a particular origin)
		- **Access-Control-Max-Age** ( cache how long can I communicate with the origin before another pre-flight)
		- **Access-Control-Allow-Methods** (allowed HTTP methods)
		- **Access-Control-Allow-Headers** (allowed headers)

- ## S3 Events
	- When enabled, a notification is generated when a certain thing happens in an S3
	- Can be delivered to SQS, SNS, and Lambda Functions
	- Object created notifications (Put, Post, Copy, CompleteMultiPartUpload)
	- Object Delete (*, Delete, DeleteMarkerCreated)
	- Object Restore ( Post-initiated, completed)
	- Replication ( OperationMissedThreshold, OperationReplacedAfterThreshold, OperationNotTracked, OperationFailedReplication )
	- Must allow services (SQS,SNS,Lambda) to communicate to S3
	- ![[Screenshot 2024-03-15 at 00.44.22.png]]
	- EventBridge is an alternative!

- ## S3 Access Logs
	 -   ![[Screenshot 2024-03-15 at 01.04.48.png]]

- ## S3 Requester Pays
	 -  ![[Screenshot 2024-03-15 at 01.09.33.png]]

- ## S3 Object Lock
	
	- it is a group of related features- enabled on 'new' buckets (support required for existing)
	- Write-once-read-many - no delete, no overwrite
	- Requires versioning - individual versions are locked
	- 1. retention periods (days / years)
	- 2. legal holds
	- Both, One, none
	- A Bucket can have default Object Lock settings
	
	- Retention Period Modes:
		1. **Compliance** - Can't be adjusted, delete, overwritten (on objects or locks) **even by the account root user**, until retention expires
		2. **Governance** - special permissions can be granted allowing lock settings to be adjusted
			1. *s3:BypassGovernanceRetention*
			2. *x-amz-bypass-governance-retention:true*
	
	- Legal Hold:
		- **On or Off**
		- no retention
		- **NO DELETES or Changes until removed**
		- *s3:PutObjectLegalHold*
		- Prevent accidental deletion of critical object versions
	


# Next Chapter: [[Chapter 4 - Security]]
#AWS_Learning 





















